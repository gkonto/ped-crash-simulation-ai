{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pedestrian Crash - Recurrent Autoregressive NN\n",
    "\n",
    "## Read the dataset\n",
    "\n",
    "I am reading the dataset from a file.\n",
    "The dataset contains timeseries for the XYZ coordinate of the head of the pedestrian.\n",
    "I will try to predict the next x coordinate, given the previous series.\n",
    "\n",
    "In the previous section, we built a single-step baseline model that simply predicted the\n",
    "last known value. For multi-step models, we’ll predict more than one timestep into\n",
    "the future. In this case, we’ll forecast the traffic volume for the next 24 hours of data\n",
    "given an input of 24 hours.\n",
    "Again, the first step is to generate the appropriate window of data. Because we wish\n",
    "to predict 24 timesteps into the future with an input of 24 hours, the input width is 24,\n",
    "the label width is 24, and the shift is also 24.\n",
    "\n",
    "\n",
    "AUTO DEN EXEI TELEIOSEI, NA VALO TO TEST SET GIA TRAINING< GIA NA DO TI THA GINEI. TORA EINAI POLU DUSKOLA NA EKPAIDEUTEI, THELEI POLLU ORA,\n",
    "OPOTE OTAN EIMAI SIGOYROS, NA VALO TO MEGALO..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from src.dataset_reader import DatasetReaderCSV\n",
    "from src.utilities import to_scrollable_table\n",
    "from src.plot import plot_car_attributes_onehot, plot_pedestrian_attributes, plot_timeseries_random_entry\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the dataset\n",
    "\n",
    "I am reading the dataset from a file.\n",
    "I've previously exported the dataset using another script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = Path(\"C:\\\\Users\\geork\\projects\\AIThesis\\src\\datasets\\head_coordinates_time_series\\\\train_set.csv\")\n",
    "test_path  = Path(\"C:\\\\Users\\geork\\projects\\AIThesis\\src\\datasets\\head_coordinates_time_series\\\\test_set.csv\")\n",
    "val_path   = Path(\"C:\\\\Users\\geork\\projects\\AIThesis\\src\\datasets\\head_coordinates_time_series\\\\validation_set.csv\")\n",
    "\n",
    "\n",
    "reader = DatasetReaderCSV(train_path)\n",
    "reader.read()\n",
    "train_df = reader.convert_to_dataframe()\n",
    "train_df = train_df.drop(columns=[\"Position\", \"Path\"], errors=\"ignore\")\n",
    "\n",
    "reader = DatasetReaderCSV(test_path)\n",
    "reader.read()\n",
    "test_df = reader.convert_to_dataframe()\n",
    "test_df = test_df.drop(columns=[\"Position\", \"Path\"], errors=\"ignore\")\n",
    "\n",
    "reader = DatasetReaderCSV(val_path)\n",
    "reader.read()\n",
    "val_df = reader.convert_to_dataframe()\n",
    "val_df = val_df.drop(columns=[\"Position\", \"Path\"], errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.describe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = train_df.isna().sum() + test_df.isna().sum() + val_df.isna().sum()\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming val_df is already defined and contains the required data\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(13, 18))\n",
    "\n",
    "# Plot Head_X_Coordinate\n",
    "axes[0].plot(val_df['Head_X_Coordinate'])\n",
    "axes[0].set_xlabel('Timestep')\n",
    "axes[0].set_ylabel('Head_X_Coordinate')\n",
    "axes[0].set_title('Head X Coordinate over Time')\n",
    "axes[0].set_xlim(0, len(val_df['Head_X_Coordinate']))\n",
    "\n",
    "# Plot Head_Y_Coordinate\n",
    "axes[1].plot(val_df['Head_Y_Coordinate'])\n",
    "axes[1].set_xlabel('Timestep')\n",
    "axes[1].set_ylabel('Head_Y_Coordinate')\n",
    "axes[1].set_title('Head Y Coordinate over Time')\n",
    "axes[1].set_xlim(0, len(val_df['Head_Y_Coordinate']))\n",
    "\n",
    "# Plot Head_Z_Coordinate\n",
    "axes[2].plot(val_df['Head_Z_Coordinate'])\n",
    "axes[2].set_xlabel('Timestep')\n",
    "axes[2].set_ylabel('Head_Z_Coordinate')\n",
    "axes[2].set_title('Head Z Coordinate over Time')\n",
    "axes[2].set_xlim(0, len(val_df['Head_Z_Coordinate']))\n",
    "\n",
    "# Adjust layout\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_window import DataWindow\n",
    "from src.autoregressive import AutoRegressive, compile_and_fit\n",
    "\n",
    "#multi_window = DataWindow(input_width=200, label_width=101, shift=301, label_columns=[\"Head_X_Coordinate\", \"Head_Y_Coordinate\", \"Head_Z_Coordinate\"])\n",
    "multi_window = DataWindow(200, 101, 301, train_df, val_df, test_df, \n",
    "                          label_columns=[\"Head_X_Coordinate\"])\n",
    "\n",
    "AR_LSTM = AutoRegressive(units=32, out_steps=101, train_df=train_df)\n",
    "history = compile_and_fit(AR_LSTM, multi_window, 3, 1)\n",
    "\n",
    "# Assume `window` is an object containing your training and validation data\n",
    "history = compile_and_fit(AR_LSTM, multi_window, checkpoint_path='C:\\\\Users\\geork\\projects\\AIThesis\\src\\checkpoint_rnn_models')\n",
    "\n",
    "\n",
    "ms_val_performance = {}\n",
    "ms_performance = {}\n",
    "ms_val_performance[\"AR - LSTM\"] = AR_LSTM.evaluate(multi_window.val)\n",
    "ms_performance[\"AR - LSTM\"] = AR_LSTM.evaluate(multi_window.test, verbose=0)\n",
    "\n",
    "multi_window.plot(AR_LSTM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
